# 1. Install and import libraries
import spacy
import os

# 2. Load the spaCy model
nlp = spacy.load('en_core_web_lg')
# (Only run the above line once after installing the model. Then you can comment it out.)

# 3. Define your collection of text files
collection = 'fromTheFires'  # <-- YOUR folder name

# 4. Choose the "word of interest"
word_of_interest_text = 'fire'  # <-- you can change this to whatever word you want
word_of_interest = nlp(word_of_interest_text)[0]  # Only grabbing the first token

# 5. Function to read and process each file
def readTextFiles(filepath):
    with open(filepath, 'r', encoding='utf8') as f:
        readFile = f.read()
        stringFile = str(readFile)

        # Use spaCy to tokenize and vectorize
        tokens = nlp(stringFile)

        # Create a dictionary to store similar words
        similar_words = {}

        for token in tokens:
            # Check token validity
            if token.has_vector and not token.is_stop and not token.is_punct:
                similarity = word_of_interest.similarity(token)
                if similarity > 0.3:  # Threshold
                    similar_words[token.text] = similarity

        # Print results
        print(f"\nSimilar words found in {filepath}:")
        for word, sim_value in sorted(similar_words.items(), key=lambda x: x[1], reverse=True):
            print(f"  {word}: {sim_value:.3f}")

# 6. Read all files in the collection
for file in os.listdir(collection):
    if file.endswith(".txt"):
        filepath = f"{collection}/{file}"
        readTextFiles(filepath)
